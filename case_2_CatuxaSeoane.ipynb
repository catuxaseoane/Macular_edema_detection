{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7349c28",
   "metadata": {},
   "source": [
    "# Practice case 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99ed5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import math\n",
    "import imutils\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef8a7cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/albumentations-team/albumentations\n",
      "  Cloning https://github.com/albumentations-team/albumentations to c:\\users\\34619\\appdata\\local\\temp\\pip-req-build-zw9mgzay\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from albumentations==1.1.0) (1.22.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\34619\\anaconda3\\lib\\site-packages (from albumentations==1.1.0) (1.6.2)\n",
      "Requirement already satisfied: scikit-image<0.19,>=0.16.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from albumentations==1.1.0) (0.18.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\34619\\anaconda3\\lib\\site-packages (from albumentations==1.1.0) (5.4.1)\n",
      "Requirement already satisfied: qudida>=0.0.4 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from albumentations==1.1.0) (0.0.4)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from albumentations==1.1.0) (4.5.5.64)\n",
      "Requirement already satisfied: opencv-python-headless>=4.0.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations==1.1.0) (4.5.5.64)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\34619\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations==1.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations==1.1.0) (0.24.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (3.4.0)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (8.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\34619\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image<0.19,>=0.16.1->albumentations==1.1.0) (5.0.6)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.1.0) (2.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/albumentations-team/albumentations 'C:\\Users\\34619\\AppData\\Local\\Temp\\pip-req-build-zw9mgzay'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imagecorruptions in c:\\users\\34619\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: opencv-python>=3.4.5 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from imagecorruptions) (4.5.5.64)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from imagecorruptions) (1.6.2)\n",
      "Requirement already satisfied: scikit-image>=0.15 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from imagecorruptions) (0.18.1)\n",
      "Requirement already satisfied: Pillow>=5.4.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from imagecorruptions) (8.2.0)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from imagecorruptions) (1.22.2)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-image>=0.15->imagecorruptions) (3.4.0)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-image>=0.15->imagecorruptions) (2.5)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-image>=0.15->imagecorruptions) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-image>=0.15->imagecorruptions) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from scikit-image>=0.15->imagecorruptions) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15->imagecorruptions) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15->imagecorruptions) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15->imagecorruptions) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15->imagecorruptions) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\34619\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15->imagecorruptions) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\34619\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.15->imagecorruptions) (5.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/albumentations-team/albumentations\n",
    "!pip install imagecorruptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d04bde3",
   "metadata": {},
   "source": [
    "Preparing data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e78173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'output/'\n",
    "# load repo with data if it is not exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print('Loading data...')\n",
    "x_train_dir = os.path.join(DATA_DIR, 'train/Images')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'train/GT')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'val/Images')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'val/GT')\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'test/Images')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'test/GT')\n",
    "\n",
    "mypath='output/train/Images'\n",
    "onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "images = np.empty(len(onlyfiles), dtype=object)\n",
    "for n in range(0, len(onlyfiles)):\n",
    "    images[n] = cv2.imread( join(mypath,onlyfiles[n]) )    \n",
    "    original=images[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b133bb9f",
   "metadata": {},
   "source": [
    "Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29d1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "\n",
    "    CLASSES = ['0']\n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids =os.listdir(images_dir)\n",
    "        \n",
    "        \n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps =[os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "\n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        #IMAGES\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image=cv2.resize(image, dsize=(1280,384), interpolation=cv2.INTER_CUBIC)\n",
    "        image=torch.from_numpy(np.array(image.transpose(2,1,0))).float()\n",
    "        \n",
    "        \n",
    "        #GT\n",
    "        mask = cv2.imread(self.masks_fps[i])\n",
    "        mask=cv2.resize(mask, dsize=(1280,384), interpolation=cv2.INTER_CUBIC)\n",
    "        mask=torch.from_numpy(np.array(mask.transpose(2,1,0))).float()\n",
    "        \n",
    "\n",
    "        # If you want to use augmentation...\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # If you apply preprocessing...\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "dataset = Dataset(x_train_dir, y_train_dir, classes=['0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb043a",
   "metadata": {},
   "source": [
    "Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d36e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['0']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cpu' \n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.Unet(encoder_name='resnet50', encoder_weights='imagenet', in_channels=3, classes=1)\n",
    "#model= smp.FPN('resnet34', in_channels=3)\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22a0253",
   "metadata": {},
   "source": [
    "Preparing DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589eb76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=None, \n",
    "    preprocessing=None,\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    x_valid_dir, \n",
    "    y_valid_dir, \n",
    "    augmentation=None, \n",
    "    preprocessing=None,\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abda2355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "# IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index\n",
    "\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a912c833",
   "metadata": {},
   "source": [
    "Create epoch runners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41265fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f8e08",
   "metadata": {},
   "source": [
    "We go through epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae38c2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 42/42 [03:45<00:00,  5.37s/it, dice_loss - -10.58, iou_score - 22.32]  \n",
      "valid: 100%|██████████| 19/19 [00:38<00:00,  2.02s/it, dice_loss - -14.92, iou_score - 30.12]\n",
      "30.115647366172393\n",
      "Model saved!\n",
      "\n",
      "Epoch: 1\n",
      "train: 100%|██████████| 42/42 [04:13<00:00,  6.04s/it, dice_loss - -23.04, iou_score - 54.2] \n",
      "valid: 100%|██████████| 19/19 [00:37<00:00,  1.98s/it, dice_loss - -43.82, iou_score - 69.16]\n",
      "69.15803450032284\n",
      "Model saved!\n",
      "\n",
      "Epoch: 2\n",
      "train: 100%|██████████| 42/42 [04:13<00:00,  6.05s/it, dice_loss - -36.83, iou_score - 78.87]\n",
      "valid: 100%|██████████| 19/19 [00:37<00:00,  1.97s/it, dice_loss - -16.68, iou_score - 8.176]\n",
      "8.175912455508582\n",
      "\n",
      "Epoch: 3\n",
      "train: 100%|██████████| 42/42 [04:12<00:00,  6.01s/it, dice_loss - -49.01, iou_score - 85.35]\n",
      "valid: 100%|██████████| 19/19 [00:37<00:00,  1.96s/it, dice_loss - 20.75, iou_score - 39.14] \n",
      "39.14050471331728\n",
      "\n",
      "Epoch: 4\n",
      "train: 100%|██████████| 42/42 [04:14<00:00,  6.07s/it, dice_loss - 58.04, iou_score - 72.68] \n",
      "valid: 100%|██████████| 19/19 [00:38<00:00,  2.02s/it, dice_loss - -41.71, iou_score - 11.85]\n",
      "11.852736084084762\n",
      "\n",
      "Epoch: 5\n",
      "train: 100%|██████████| 42/42 [04:14<00:00,  6.07s/it, dice_loss - -92.35, iou_score - 69.64]\n",
      "valid: 100%|██████████| 19/19 [00:37<00:00,  1.96s/it, dice_loss - -9.802, iou_score - 4.389]\n",
      "4.38928948264373\n",
      "\n",
      "Epoch: 6\n",
      "train: 100%|██████████| 42/42 [04:15<00:00,  6.09s/it, dice_loss - -32.77, iou_score - 29.48]\n",
      "valid: 100%|██████████| 19/19 [00:37<00:00,  1.97s/it, dice_loss - -102.2, iou_score - 140.0]\n",
      "139.97791551122148\n",
      "Model saved!\n",
      "\n",
      "Epoch: 7\n",
      "train: 100%|██████████| 42/42 [04:13<00:00,  6.03s/it, dice_loss - -14.03, iou_score - 90.15]\n",
      "valid: 100%|██████████| 19/19 [00:37<00:00,  1.99s/it, dice_loss - -134.1, iou_score - 90.4] \n",
      "90.39750593508543\n",
      "\n",
      "Epoch: 8\n",
      "train: 100%|██████████| 42/42 [04:22<00:00,  6.25s/it, dice_loss - -43.68, iou_score - 71.01]\n",
      "valid:  89%|████████▉ | 17/19 [00:35<00:04,  2.10s/it, dice_loss - -53.48, iou_score - 30.34]   "
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "#epoches=10\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    print(valid_logs['iou_score'])\n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['iou_score']:\n",
    "        max_score = valid_logs['iou_score']\n",
    "        torch.save(model, './best_model.pth')\n",
    "        print('Model saved!')\n",
    "        \n",
    "    if i == 25:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ffcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "best_model = torch.load('./best_model.pth')\n",
    "# create test dataset\n",
    "test_dataset = Dataset(\n",
    "    x_test_dir, \n",
    "    y_test_dir, \n",
    "    augmentation=None, \n",
    "    preprocessing=None,\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset)\n",
    "# evaluate model on test set\n",
    "test_epoch = smp.utils.train.ValidEpoch(\n",
    "    model=best_model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "logs = test_epoch.run(test_dataloader)\n",
    "print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234aa831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for data visualization\n",
    "def visualize2(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        (h, w) = image.shape[:2]\n",
    "        (cX, cY) = (w // 2, h // 2)\n",
    "        # rotate \n",
    "        M = cv2.getRotationMatrix2D((cX, cY), 90, 1.0)\n",
    "        rotated = cv2.warpAffine(image, M, (w, h))\n",
    "        plt.imshow(rotated)\n",
    "    plt.show()\n",
    "    \n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "# test dataset without transformations for image visualization\n",
    "\n",
    "test_dataset_vis = Dataset(\n",
    "    x_test_dir, y_test_dir, \n",
    "    classes=CLASSES,\n",
    ")\n",
    "for i in range(1):\n",
    "    n = np.random.choice(len(test_dataset))\n",
    "    \n",
    "    image_vis = test_dataset_vis[n][0].numpy().astype('uint8')\n",
    "    image, gt_mask = test_dataset[n]\n",
    "    \n",
    "    gt_mask = gt_mask.numpy().astype('uint8').squeeze()\n",
    "    \n",
    "    x_tensor = torch.from_numpy(np.asarray(image)).to(DEVICE).unsqueeze(0)\n",
    "    pr_mask = best_model.predict(x_tensor)\n",
    "    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n",
    "        \n",
    "    '''print(image_vis.transpose(2,1,0).shape)\n",
    "    print(gt_mask.transpose(2,1,0).shape)\n",
    "    print(pr_mask.shape)'''\n",
    "        \n",
    "    visualize(image=image_vis.transpose(2,1,0), \n",
    "        ground_truth_mask=gt_mask.transpose(2,1,0),\n",
    "        predicted_mask=pr_mask\n",
    "    )\n",
    "    \n",
    "    \n",
    "#mask=torch.from_numpy(np.array(mask.transpose(2,1,0))).float()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf870ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2511f644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
